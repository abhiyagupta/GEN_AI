{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gyfJIA4Uzy5"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2F-qpOK3jDy",
    "outputId": "5647c510-7590-4174-d01c-83f44f9299e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.28.tar.gz (9.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.28-cp310-cp310-manylinux_2_35_x86_64.whl size=8739347 sha256=bda5d3294f4372501131068e193215587f8b1591bce4863c0aa0798f95bf4833\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/6e/a9/478cce089dc2a082bdcffe468a1c65465c91b25d911b30da82\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: llama-cpp-python\n",
      "Successfully installed llama-cpp-python-0.2.28\n"
     ]
    }
   ],
   "source": [
    "# Installation for GPU llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZYAmbRJUEbM"
   },
   "outputs": [],
   "source": [
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFZj9kr8Pahl"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3gwxSqQPahl"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKcL7M9r1Uo3"
   },
   "source": [
    "# Llama2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5K3mCDr407D"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKcktmfa45ke"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\" # the model is in gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "d4f8a3bd06bd4c34b47c9d1bca18e640",
      "b6804cb24e3245a2b68b7ca5016464d7",
      "f9d7cdae14e746e6a9e2147bff90025a",
      "de5f7ac281014fdd83e331ab70db2805",
      "bbb5a6640e594e50926ee5541e55f9fc",
      "795f3c6dc2e048109e5afd6e4b52bc6f",
      "8869bf759b85433ab3f4edd0cedb16a1",
      "a05f713b4e2c4956b5610fd1ada4c512",
      "b9d53223d8e0442ba94f19e773072483",
      "6f787ae6b8144581ad96c1ec919b85b1",
      "ccac73e43faf4b2aa9bae47b6ba09e58"
     ]
    },
    "id": "k7HQra5c46V-",
    "outputId": "93872b9c-280d-4071-c74e-a8a706c9aa32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f8a3bd06bd4c34b47c9d1bca18e640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama-2-13b-chat.Q5_K_M.gguf:   0%|          | 0.00/9.23G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path,\n",
    "    filename=model_basename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hd_9HkIl4_9q",
    "outputId": "f5bfe991-f34f-4db5-cf02-02ad6d537af9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=43, # Change this value based on your model and your GPU VRAM pool.\n",
    "    n_ctx=4096 # Context window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC4111SC1AVv"
   },
   "outputs": [],
   "source": [
    "llama2_prompt_template = \"\"\"<s>[INST]<<SYS>>\n",
    "{system_message}\n",
    "<</SYS>>\n",
    "\n",
    "{user_message}[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtK5EoQfZ5nE"
   },
   "source": [
    "## Self-consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJqjso69Z7-p"
   },
   "source": [
    "In self-consistency, we generate multiple answers to the same question and pick the answer that is repeated the most across these occurrences. This is particularly valuable for factual questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAc2CWEjdcLr"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an assistant tasked to answer queries on financial information.\n",
    "Do not repeat the question. Only answer the question presented by the user.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaewayTKZ6ve"
   },
   "outputs": [],
   "source": [
    "answers_template = \"\"\"\n",
    "Context:\n",
    "{context}\n",
    "===\n",
    "Using the context above generate {num_answers} distinct answers to the following question:\n",
    "Question:\n",
    "{question}.\n",
    "\n",
    "Arrange your answers in numbered bullet points.\n",
    "Present only the answers in bullet points.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wahaaiphc7OT"
   },
   "source": [
    "Here is an extract from the [Tesla 2022 10-K](https://www.sec.gov/Archives/edgar/data/1318605/000095017023001409/tsla-20221231.htm) statement that will be used as context for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCkZEt2Xc36X"
   },
   "outputs": [],
   "source": [
    "tesla_annual_report_context =\"\"\"\n",
    "In 2022, we recognized total revenues of $81.46 billion, respectively, representing an increase of $27.64 billion, compared to the prior year.\n",
    "We continue to ramp production, build new manufacturing capacity and expand our operations to enable increased deliveries and deployments of our products and further revenue growth.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxiNJaIjdH6a"
   },
   "outputs": [],
   "source": [
    "factual_question = \"What was the increase in annual revenue in 2022 compared to 2021?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcBK0BS42DrC"
   },
   "outputs": [],
   "source": [
    "answers_prompt = llama2_prompt_template.format(\n",
    "    system_message=system_message,\n",
    "    user_message=answers_template.format(\n",
    "        context=tesla_annual_report_context,\n",
    "        question=factual_question,\n",
    "        num_answers=3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwuF7duDd4c0",
    "outputId": "a280dab1-385c-4f58-be8e-980e9f336ebf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=answers_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxJ1b0x2eJRa",
    "outputId": "94bd91c0-0371-457e-f596-c5c52b90ae61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure, here are three distinct answers to the question \"What was the increase in annual revenue in 2022 compared to 2021?\" based on the provided context:\n",
      "\n",
      "1. The increase in annual revenue in 2022 compared to 2021 was $27.64 billion.\n",
      "2. Our annual revenues grew by 38% from 2021 to 2022, totaling $81.46 billion.\n",
      "3. We experienced a significant increase in revenue of $27.64 billion between 2021 and 2022, bringing our total annual revenues to $81.46 billion.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUPi-RGngejm"
   },
   "outputs": [],
   "source": [
    "factual_answers = response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o2Yp8Omj4GN"
   },
   "outputs": [],
   "source": [
    "consistency_template = \"\"\"\n",
    "Here are {num_answers} answers to the question mentioned below:\n",
    "Question:\n",
    "{question}\n",
    "Answers:\n",
    "{answers}\n",
    "\n",
    "Observe the answers mentioned above and choose the answer that occurs most.\n",
    "Present only the most frequent solution in the following format.\n",
    "Final Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uA6pj-LB31_n"
   },
   "outputs": [],
   "source": [
    "consistency_prompt = llama2_prompt_template.format(\n",
    "    system_message=system_message,\n",
    "    user_message=consistency_template.format(\n",
    "        num_answers=3,\n",
    "        question=factual_question,\n",
    "        answers=factual_answers\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbEtfTi2k4Ao",
    "outputId": "15b61fb9-38e9-40ae-bd2f-0d80690bbe88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=consistency_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcW6E86UlLyJ",
    "outputId": "feab2902-7423-4efc-8f66-345ae7aa3d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure! Based on the provided context, the most frequent answer is:\n",
      "\n",
      "Final Answer: The increase in annual revenue in 2022 compared to 2021 was $27.64 billion.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihVZtA6cl2ak"
   },
   "source": [
    "## Tree-of-Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-3pbuuymH_a"
   },
   "source": [
    "Tree-of-thought prompting is a generalization of chain-of-thought prompting where the model is prompted to take multiple reasoning paths. This forces the LLM into a deliberate reasoning mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xA4QfylvlN-H"
   },
   "outputs": [],
   "source": [
    "solutions_template = \"\"\"\n",
    "Generate {num_solutions} distinct solutions for the following problem:\n",
    "Problem:\n",
    "{problem}.\n",
    "--\n",
    "\n",
    "Consider the following factors in coming up with your solutions.\n",
    "Factors:\n",
    "{factors}\n",
    "\n",
    "Present the solutions in numbered bullet points. Present only the solutions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTDkAqy1m3IN"
   },
   "outputs": [],
   "source": [
    "climate_problem = \"Reduce the impact of climate change on the occurrence of extreme events in the Earth's atmosphere.\"\n",
    "\n",
    "climate_factors = \"\"\"\n",
    "1. Renewable Energy Transition\n",
    "2. Reforestation\n",
    "3. Sustainable Agricultural Practises\n",
    "4. Carbon capture and storage\n",
    "5. Climate-resilient infrastructure\n",
    "6. Circular economy practises\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXN-AMsk7Jrh"
   },
   "outputs": [],
   "source": [
    "solutions_prompt = llama2_prompt_template.format(\n",
    "    system_message='',\n",
    "    user_message=solutions_template.format(\n",
    "        num_solutions=3,\n",
    "        problem=climate_problem,\n",
    "        factors=climate_factors\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJggcQ2_7X00",
    "outputId": "c4d8529d-f5a8-454b-b5e7-08b06c5c7910"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=solutions_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTOCaSeY7dUd",
    "outputId": "ac6e4d44-6ca6-488f-902b-685486c74546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure, here are three distinct solutions for reducing the impact of climate change on extreme events:\n",
      "\n",
      "Solution 1: Renewable Energy Transition\n",
      "\n",
      "• Accelerate the transition to renewable energy sources such as wind and solar power to reduce dependence on fossil fuels and lower carbon emissions.\n",
      "• Invest in research and development of new technologies to improve efficiency and affordability of renewables.\n",
      "• Implement policies to promote the adoption of renewables, such as tax credits or feed-in tariffs.\n",
      "\n",
      "Solution 2: Reforestation and Sustainable Land Use\n",
      "\n",
      "• Restore degraded lands and forests to their natural state through reforestation efforts.\n",
      "• Implement sustainable agricultural practices that promote soil health, biodiversity, and carbon sequestration.\n",
      "• Promote agroforestry techniques that integrate trees into farming systems.\n",
      "\n",
      "Solution 3: Climate-Resilient Infrastructure and Circular Economy Practices\n",
      "\n",
      "• Build climate-resilient infrastructure such as sea walls, levees, and green roofs to protect communities from extreme weather events.\n",
      "• Implement circular economy practices that reduce waste and promote the reuse and recycling of materials.\n",
      "• Invest in research and development of new technologies that support a more sustainable and resilient infrastructure.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzFzNkO0rqHq"
   },
   "outputs": [],
   "source": [
    "climate_solutions = response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLtVhH_JqxxV"
   },
   "outputs": [],
   "source": [
    "evaluation_template = \"\"\"\n",
    "For the following problem: {problem}, evaluate each solution in the following proposed solutions: \\n{solutions}\\n.\n",
    "\n",
    "Analyze pros, cons, feasibility, and probability of success for each solution.\n",
    "Present your evaluations of each solution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "202L4qjH7qtA"
   },
   "outputs": [],
   "source": [
    "evaluations_prompt = llama2_prompt_template.format(\n",
    "    system_message='',\n",
    "    user_message=evaluation_template.format(\n",
    "        problem=climate_problem,\n",
    "        solutions=climate_solutions\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_mZZACPrwts",
    "outputId": "58855825-8402-488c-af02-6e5636477cda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=evaluations_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtiuyEJNr3yD"
   },
   "outputs": [],
   "source": [
    "climate_proposal_evaluations = response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cVz9esJr914",
    "outputId": "84911c4f-9ca2-4a49-b2a9-858eba73a21d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure! Here are my evaluations of the three proposed solutions to reduce the impact of climate change on extreme events:\n",
      "\n",
      "Solution 1: Renewable Energy Transition\n",
      "\n",
      "Pros:\n",
      "\n",
      "* Reduces dependence on fossil fuels and lowers carbon emissions, which contribute to climate change.\n",
      "* Can create jobs and stimulate economic growth in the renewable energy sector.\n",
      "* Improves air quality and public health by reducing pollution from fossil fuel combustion.\n",
      "\n",
      "Cons:\n",
      "\n",
      "* Requires significant investment in infrastructure and technology development.\n",
      "* May face resistance from fossil fuel industries and communities reliant on them.\n",
      "* Intermittent nature of renewable energy sources can create power grid stability challenges.\n",
      "\n",
      "Feasibility: High probability of success, as many countries have already made significant progress in transitioning to renewable energy sources. However, the pace of transition needs to be accelerated to meet climate change mitigation goals.\n",
      "\n",
      "Probability of Success: 8/10\n",
      "\n",
      "Solution 2: Reforestation and Sustainable Land Use\n",
      "\n",
      "Pros:\n",
      "\n",
      "* Can sequester significant amounts of carbon dioxide from the atmosphere, reducing greenhouse gas emissions.\n",
      "* Improves biodiversity and ecosystem health by restoring degraded lands and forests.\n",
      "* Supports sustainable agriculture practices that promote soil health and food security.\n",
      "\n",
      "Cons:\n",
      "\n",
      "* Requires significant land area to achieve meaningful carbon sequestration.\n",
      "* Can be challenging to implement in areas with high population density or competing land uses.\n",
      "* May face resistance from industries reliant on deforestation, such as logging and agriculture.\n",
      "\n",
      "Feasibility: Moderate probability of success, as reforestation efforts are already underway but need to be scaled up significantly to meet climate change mitigation goals.\n",
      "\n",
      "Probability of Success: 6/10\n",
      "\n",
      "Solution 3: Climate-Resilient Infrastructure and Circular Economy Practices\n",
      "\n",
      "Pros:\n",
      "\n",
      "* Protects communities from extreme weather events by building climate-resilient infrastructure.\n",
      "* Reduces waste and promotes sustainable resource use through circular economy practices.\n",
      "* Can create jobs and stimulate economic growth in the green infrastructure sector.\n",
      "\n",
      "Cons:\n",
      "\n",
      "* Requires significant investment in infrastructure development and research & development of new technologies.\n",
      "* May face resistance from industries reliant on traditional infrastructure and resource extraction methods.\n",
      "* Can be challenging to implement in areas with limited resources or governance capacity.\n",
      "\n",
      "Feasibility: Moderate probability of success, as many countries have already begun investing in climate-resilient infrastructure and circular economy practices. However, the pace of implementation needs to be accelerated to meet climate change mitigation goals.\n",
      "\n",
      "Probability of Success: 7/10\n",
      "\n",
      "In conclusion, all three solutions offer significant benefits for reducing the impact of climate change on extreme events, but their feasibility and probability of success vary depending on factors such as investment, governance, and public support. Accelerating the transition to renewable energy sources is likely the most critical solution, as it can address multiple aspects of the climate crisis, including greenhouse gas emissions and air pollution. Reforestation and sustainable land use practices are also essential for sequestering carbon dioxide and improving ecosystem health, but their implementation will require significant investment and coordination. Finally, building climate-resilient infrastructure and promoting circular economy practices can protect communities from extreme weather events and promote sustainable development, but may face resistance from vested interests and require careful planning and governance.\n"
     ]
    }
   ],
   "source": [
    "print(climate_proposal_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Df71uD8Br9No"
   },
   "outputs": [],
   "source": [
    "ranking_template = \"\"\"\n",
    "For the following problem: {problem}, rank the solutions presented in the following evaluations: \\n{evaluations}\\n.\n",
    "Pick most promising solution and present implementation strategies and methods to handle potential obstacles for this solution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gJ_FQds81wV"
   },
   "outputs": [],
   "source": [
    "ranking_prompt = llama2_prompt_template.format(\n",
    "    system_message='',\n",
    "    user_message=ranking_template.format(\n",
    "        problem=climate_problem,\n",
    "        evaluations=climate_proposal_evaluations\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGXksQ9N9DI9",
    "outputId": "fd4f067f-132b-4e0e-fc3b-efbd5dee1b2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=ranking_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLqUJY-HxmiP"
   },
   "outputs": [],
   "source": [
    "climate_proposal_rankings = response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9KgrfQkzJ_N",
    "outputId": "de7d0073-aced-4077-c1d5-44493c553b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Based on the evaluations provided, the most promising solution for reducing the impact of climate change on extreme events is the transition to renewable energy sources. This solution has a high probability of success, as many countries have already made significant progress in transitioning to renewable energy sources, and it addresses multiple aspects of the climate crisis, including greenhouse gas emissions and air pollution.\n",
      "\n",
      "To implement this solution effectively, the following implementation strategies can be considered:\n",
      "\n",
      "1. Increase investment in renewable energy infrastructure: Governments and private investors should increase their investment in renewable energy technologies such as wind, solar, hydroelectric, and geothermal power. This will help to reduce our reliance on fossil fuels and lower carbon emissions.\n",
      "2. Implement policies to support the transition: Governments can implement policies such as tax credits, feed-in tariffs, and renewable portfolio standards to incentivize the use of renewable energy sources. These policies can help to level the playing field for renewables and make them more competitive with fossil fuels.\n",
      "3. Promote research and development: Continuous research and development are necessary to improve the efficiency, reliability, and affordability of renewable energy technologies. Governments and private companies should invest in R&D to develop new technologies that can help to reduce our dependence on fossil fuels.\n",
      "4. Build public support for the transition: Building public support for the transition to renewable energy sources is critical to overcoming resistance from vested interests and ensuring a smooth transition. Public education campaigns, community engagement, and stakeholder consultation can help to build support for the transition.\n",
      "5. Address potential obstacles: Potential obstacles to the transition to renewable energy sources include intermittency, land use conflicts, and grid integration issues. To address these challenges, governments and private companies should invest in energy storage technologies, develop smart grids that can integrate renewables into the power system, and work with communities to identify suitable locations for renewable energy projects.\n",
      "6. Encourage international cooperation: Climate change is a global problem that requires international cooperation. Countries should work together to share knowledge, technology, and best practices in transitioning to renewable energy sources. International agreements such as the Paris Agreement can help to coordinate efforts and ensure that all countries are doing their part to address climate change.\n",
      "\n",
      "In conclusion, accelerating the transition to renewable energy sources is the most promising solution for reducing the impact of climate change on extreme events. To implement this solution effectively, a combination of investment, policy support, research and development, public education, and international cooperation are necessary. By working together, we can create a more sustainable future for all.\n"
     ]
    }
   ],
   "source": [
    "print(climate_proposal_rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czBuw5wv9_yR"
   },
   "source": [
    "# Mistral 7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad8dtJJm9_yd"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScvUkGoK9_yd"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q5_K_M.gguf\" # the model is in gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "95ee15a3eaa44f4b836b462e2c969a97",
      "f129f14dd3f14f88940265511593b996",
      "1ae397d2d6c04acd80929a63d321a84b",
      "30b74747ed4c4db784f29cc1eda1b797",
      "4bf81c0bff484b7e98bac2eae579ef3b",
      "d6f14ce72aec4a26a74a30841008ca1c",
      "36ed7ed1c8b3429496efa05cb33cb1cf",
      "9240e7b45bfb4806affa664c491c0971",
      "9e4305a1f8684745a6c549bbc8e27e4a",
      "1870eb8083ef43838e21d9cbdf485e93",
      "04eb07dcd94e49299aace343b44b8f03"
     ]
    },
    "id": "NGmdZWdJ9_yd",
    "outputId": "22f9e5ee-3a32-4234-ce25-cfa5c7e73d60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ee15a3eaa44f4b836b462e2c969a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mistral-7b-instruct-v0.2.Q5_K_M.gguf:   0%|          | 0.00/5.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path,\n",
    "    filename=model_basename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfZcdJms9_ye",
    "outputId": "c511685d-36d2-4d1a-e233-fd2e46b0e7e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=43, # Change this value based on your model and your GPU VRAM pool.\n",
    "    n_ctx=4096 # Context window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6tMq8xt9_ye"
   },
   "outputs": [],
   "source": [
    "mistral_prompt_template = \"\"\"<s>[INST]{prompt}[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBd1IvGO9_ye"
   },
   "source": [
    "## Self-consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsCKVAbj9_ye"
   },
   "source": [
    "In self-consistency, we generate multiple answers to the same question and pick the answer that is repeated the most across these occurrences. This is particularly valuable for factual questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzHVDpvE9_yf"
   },
   "outputs": [],
   "source": [
    "answers_template = \"\"\"\n",
    "Context:\n",
    "{context}\n",
    "===\n",
    "Using the context above generate {num_answers} distinct answers to the following question:\n",
    "Question:\n",
    "{question}.\n",
    "\n",
    "Arrange your answers in numbered bullet points.\n",
    "Present only the answers in bullet points.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DnnKjMd9_yf"
   },
   "source": [
    "Here is an extract from the [Tesla 2022 10-K](https://www.sec.gov/Archives/edgar/data/1318605/000095017023001409/tsla-20221231.htm) statement that will be used as context for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qB0M43W9_yf"
   },
   "outputs": [],
   "source": [
    "tesla_annual_report_context =\"\"\"\n",
    "In 2022, we recognized total revenues of $81.46 billion, respectively, representing an increase of $27.64 billion, compared to the prior year.\n",
    "We continue to ramp production, build new manufacturing capacity and expand our operations to enable increased deliveries and deployments of our products and further revenue growth.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxBNfIBb9_yf"
   },
   "outputs": [],
   "source": [
    "factual_question = \"What was the increase in annual revenue in 2022 compared to 2021?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfFfOK7K9_yg"
   },
   "outputs": [],
   "source": [
    "answers_prompt = mistral_prompt_template.format(\n",
    "    prompt=answers_template.format(\n",
    "        context=tesla_annual_report_context,\n",
    "        question=factual_question,\n",
    "        num_answers=3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bK0_2HXp9_yg"
   },
   "outputs": [],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=answers_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgQWsrYP9_yh"
   },
   "outputs": [],
   "source": [
    "factual_answers = response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EThHefWq9_yg",
    "outputId": "d31f39eb-0260-428d-b9bc-207e0966f95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* The increase in annual revenue from 2021 to 2022 was $27.64 billion.\n",
      "* In 2022, total revenues were $81.46 billion, which is an increase of $27.64 billion compared to the previous year.\n",
      "* The company experienced a revenue growth of approximately $27.64 billion between 2021 and 2022.\n"
     ]
    }
   ],
   "source": [
    "print(factual_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z8CvXEA9_yh"
   },
   "outputs": [],
   "source": [
    "consistency_template = \"\"\"\n",
    "Here are {num_answers} answers to the question mentioned below:\n",
    "Question:\n",
    "{question}\n",
    "Answers:\n",
    "{answers}\n",
    "\n",
    "Observe the answers mentioned above and choose the answer that occurs most.\n",
    "Present only the most frequent solution in the following format.\n",
    "Final Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYEv2BOA9_yh"
   },
   "outputs": [],
   "source": [
    "consistency_prompt = mistral_prompt_template.format(\n",
    "    prompt=consistency_template.format(\n",
    "        num_answers=3,\n",
    "        question=factual_question,\n",
    "        answers=factual_answers\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBhPEaNH9_yh",
    "outputId": "77a6bbc0-3bdc-4c05-be45-bb2832446ae4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=consistency_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doqJRiyO9_yh",
    "outputId": "0a838be3-f8b6-4d98-ef29-8570c64985c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: The increase in annual revenue from 2021 to 2022 was $27.64 billion.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbDZZ24K9_yi"
   },
   "source": [
    "## Tree-of-Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23qtiQV29_yi"
   },
   "source": [
    "Tree-of-thought prompting is a generalization of chain-of-thought prompting where the model is prompted to take multiple reasoning paths. This forces the LLM into a deliberate reasoning mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObOvaY_j9_yi"
   },
   "outputs": [],
   "source": [
    "solutions_template = \"\"\"\n",
    "Generate {num_solutions} distinct solutions for the following problem:\n",
    "Problem:\n",
    "{problem}.\n",
    "--\n",
    "\n",
    "Consider the following factors in coming up with your solutions.\n",
    "Factors:\n",
    "{factors}\n",
    "\n",
    "Present the {num_solutions} solutions in numbered bullet points. Present only the solutions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTrEs2Wd9_yi"
   },
   "outputs": [],
   "source": [
    "climate_problem = \"Reduce the impact of climate change on the occurrence of extreme events in the Earth's atmosphere.\"\n",
    "\n",
    "climate_factors = \"\"\"\n",
    "1. Renewable Energy Transition\n",
    "2. Reforestation\n",
    "3. Sustainable Agricultural Practises\n",
    "4. Carbon capture and storage\n",
    "5. Climate-resilient infrastructure\n",
    "6. Circular economy practises\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CInwKcCF9_yi"
   },
   "outputs": [],
   "source": [
    "solutions_prompt = mistral_prompt_template.format(\n",
    "    prompt=solutions_template.format(\n",
    "        num_solutions=3,\n",
    "        problem=climate_problem,\n",
    "        factors=climate_factors\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZozUID1C9_yj",
    "outputId": "520dea75-0029-41bb-a7fa-6c314e4b44bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=solutions_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2T6PIF_v9_yj"
   },
   "outputs": [],
   "source": [
    "climate_solutions = response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4E2S72w9_yj",
    "outputId": "ba697e61-04d7-4b32-f594-561fb1cdbfd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution 1:\n",
      "- Accelerate the transition to renewable energy sources by investing in solar, wind, hydroelectric, and other clean energy technologies.\n",
      "- Encourage governments and businesses to set ambitious targets for reducing greenhouse gas emissions.\n",
      "- Implement policies that incentivize individuals and organizations to adopt renewable energy solutions.\n",
      "\n",
      "Solution 2:\n",
      "- Increase global reforestation efforts by planting new trees, protecting existing forests, and promoting sustainable forest management practices.\n",
      "- Encourage the use of agroforestry systems, which combine agriculture with tree cultivation, to help sequester carbon and reduce deforestation.\n",
      "- Support research into innovative approaches for afforestation (planting new forests in previously treeless areas) and reforestation (reestablishing forests on degraded or deforested land).\n",
      "\n",
      "Solution 3:\n",
      "- Implement climate-resilient infrastructure projects, such as green roofs, rainwater harvesting systems, and permeable pavements.\n",
      "- Encourage the use of sustainable agricultural practices that reduce emissions and increase carbon sequestration in soil, such as regenerative agriculture, agroforestry, and organic farming.\n",
      "- Promote circular economy practises, which minimize waste and maximize resource efficiency, to help reduce greenhouse gas emissions throughout supply chains.\n",
      "- Invest in research and development of new technologies for carbon capture and storage (CCS) to help mitigate the impact of industrial processes that are difficult to decarbonize.\n"
     ]
    }
   ],
   "source": [
    "print(climate_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdQh3kDx9_yj"
   },
   "outputs": [],
   "source": [
    "evaluation_template = \"\"\"\n",
    "For the following problem: {problem}, evaluate each solution in the following proposed solutions: \\n{solutions}\\n.\n",
    "Analyze pros, cons, feasibility, and probability of success for each solution.\n",
    "Present your evaluations of each solutions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8WNm7dr9_yj"
   },
   "outputs": [],
   "source": [
    "evaluations_prompt = mistral_prompt_template.format(\n",
    "    prompt=evaluation_template.format(\n",
    "        problem=climate_problem,\n",
    "        solutions=climate_solutions\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFRhLojH9_yj",
    "outputId": "fa538ab6-6bb6-44c7-f3ea-5e72098d786a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=evaluations_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnPDdwLQ9_yk"
   },
   "outputs": [],
   "source": [
    "climate_proposal_evaluations = response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iC8kXBr-9_yk",
    "outputId": "210beb1f-4b67-429a-ad35-124166e96f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution 1: Transitioning to Renewable Energy Sources\n",
      "Pros:\n",
      "- Reduces greenhouse gas emissions from the power sector, which is a major contributor to climate change.\n",
      "- Creates jobs and stimulates economic growth in the renewable energy industry.\n",
      "- Decreases dependence on fossil fuels, reducing vulnerability to price volatility and supply disruptions.\n",
      "Cons:\n",
      "- High upfront costs for infrastructure development and implementation of renewable energy technologies.\n",
      "- Intermittency issues with some renewable sources (e.g., solar and wind) may require backup power or energy storage solutions.\n",
      "- Political challenges in implementing policies that incentivize the transition to renewable energy, particularly in countries heavily reliant on fossil fuel industries.\n",
      "Feasibility: Renewable energy technologies have become increasingly cost-competitive with traditional fossil fuels and are continuing to improve in efficiency. Many countries have already set ambitious targets for reducing greenhouse gas emissions and increasing the share of renewables in their power mixes, indicating a strong political will to transition away from fossil fuels.\n",
      "Probability of Success: The global energy landscape is shifting towards renewable sources, with solar and wind becoming increasingly cost-competitive. However, achieving a complete transition to renewable energy will require significant investment in infrastructure development and policy support.\n",
      "\n",
      "Solution 2: Reforestation and Afforestation Efforts\n",
      "Pros:\n",
      "- Forests act as carbon sinks, absorbing CO2 from the atmosphere through photosynthesis.\n",
      "- Trees help mitigate climate change by providing shade, reducing urban heat islands, and increasing precipitation.\n",
      "- Agroforestry systems can provide food, fuel, fiber, and other ecosystem services while sequestering carbon.\n",
      "Cons:\n",
      "- Forest restoration efforts require significant resources, including land, water, labor, and capital.\n",
      "- Deforestation continues to be a major issue in many parts of the world due to agriculture, logging, mining, and infrastructure development.\n",
      "- Sustainable forest management practices may not always be economically viable or politically feasible in some regions.\n",
      "Feasibility: Reforestation and afforestation efforts have shown promising results in reducing greenhouse gas emissions and improving ecosystem health. However, achieving large-scale restoration will require significant investment and political commitment to address the root causes of deforestation.\n",
      "Probability of Success: Forest restoration initiatives have gained momentum in recent years, with many countries setting ambitious targets for reforestation and afforestation. However, success will depend on addressing the underlying drivers of deforestation and ensuring that restoration efforts are sustainable and effective over the long term.\n",
      "\n",
      "Solution 3: Climate-Resilient Infrastructure and Circular Economy Practices\n",
      "Pros:\n",
      "- Green infrastructure projects help reduce greenhouse gas emissions by increasing energy efficiency, reducing water usage, and improving air quality.\n",
      "- Sustainable agricultural practices can increase carbon sequestration in soil while also providing food security and ecosystem services.\n",
      "- Circular economy practices minimize waste and maximize resource efficiency throughout supply chains, reducing the need for raw materials extraction and associated greenhouse gas emissions.\n",
      "Cons:\n",
      "- Implementing climate-resilient infrastructure projects requires significant upfront capital investment and ongoing maintenance costs.\n",
      "- Sustainable agricultural practices may require additional resources (e.g., labor, water) or involve higher production costs compared to conventional farming methods.\n",
      "- Circular economy practices can be challenging to implement in industries with complex supply chains and high energy requirements.\n",
      "Feasibility: Climate-resilient infrastructure projects have gained increasing attention as a way to reduce greenhouse gas emissions while also improving the resilience of communities to climate change impacts. Sustainable agricultural practices are becoming more widely adopted, particularly in developing countries where food security is a major concern. Circular economy practices are gaining traction in industries such as textiles and electronics but face challenges in sectors with complex supply chains and high energy requirements.\n",
      "Probability of Success: The feasibility and probability of success for climate-resilient infrastructure projects, sustainable agricultural practices, and circular economy initiatives depend on the specific contexts in which they are implemented. While there have been notable successes in each area, widespread adoption will require significant investment, political commitment, and collaboration across sectors and stakeholders.\n"
     ]
    }
   ],
   "source": [
    "print(climate_proposal_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlhZYy349_yk"
   },
   "outputs": [],
   "source": [
    "ranking_template = \"\"\"\n",
    "For the following problem: {problem}, rank the solutions presented in the following evaluations: \\n{evaluations}\\n.\n",
    "Pick most promising solution and present implementation strategies and methods to handle potential obstacles for this solution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-Fo2XuS9_yk"
   },
   "outputs": [],
   "source": [
    "ranking_prompt = mistral_prompt_template.format(\n",
    "    prompt=ranking_template.format(\n",
    "        problem=climate_problem,\n",
    "        evaluations=climate_proposal_evaluations\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4RiDutG9_yl",
    "outputId": "41f3ec49-996d-4b31-e903-b79c1614b04f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(\n",
    "    prompt=ranking_prompt,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2,\n",
    "    echo=False # do not return the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvaJ0mMg9_yl"
   },
   "outputs": [],
   "source": [
    "climate_proposal_rankings = response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXY8jumi9_yl",
    "outputId": "3c1431d3-b046-4b2a-f8b4-d68cee568f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the evaluations provided, all three solutions - transitioning to renewable energy sources, reforestation and afforestation efforts, and climate-resilient infrastructure and circular economy practices - have their merits in reducing the impact of climate change on extreme events in the Earth's atmosphere. However, considering the current global context and the feasibility and probability of success for each solution, transitioning to renewable energy sources appears to be the most promising option.\n",
      "\n",
      "Implementation Strategies:\n",
      "1. Government Policies and Incentives: Governments can play a crucial role in implementing policies that incentivize the transition to renewable energy. This could include setting targets for reducing greenhouse gas emissions, providing subsidies or tax credits for renewable energy projects, and investing in research and development of new technologies.\n",
      "2. Public-Private Partnerships: Collaboration between governments, private companies, and international organizations can help accelerate the transition to renewable energy by sharing resources, expertise, and financing.\n",
      "3. Education and Awareness: Raising public awareness about the benefits of renewable energy and the importance of reducing greenhouse gas emissions can help build support for policy initiatives and drive demand for clean energy solutions.\n",
      "4. Technological Innovation: Continued investment in research and development of new technologies, such as advanced battery storage systems and smart grid infrastructure, can help address intermittency issues with renewable sources and ensure a reliable power supply.\n",
      "5. International Cooperation: Climate change is a global problem that requires international cooperation to solve. Countries can work together through multilateral agreements and partnerships to share knowledge, resources, and best practices for transitioning to renewable energy.\n",
      "\n",
      "Potential Obstacles and Mitigation Strategies:\n",
      "1. High Upfront Costs: To mitigate the high upfront costs of infrastructure development and implementation of renewable energy technologies, governments can provide subsidies or tax incentives to encourage private investment in renewables. Additionally, public-private partnerships can help share risks and costs between stakeholders.\n",
      "2. Intermittency Issues: Renewable sources such as solar and wind are intermittent by nature, which requires backup power or energy storage solutions. Governments and private companies can invest in research and development of advanced battery storage systems and smart grid infrastructure to ensure a reliable power supply even during periods of low renewable generation.\n",
      "3. Political Challenges: In countries heavily reliant on fossil fuel industries, transitioning to renewable energy may face political challenges. Governments can address these challenges by providing economic incentives for workers in the fossil fuel industry to transition to clean energy jobs and investing in retraining programs to help them acquire new skills. Additionally, international cooperation and partnerships can help build support for policy initiatives that promote a just transition to renewable energy.\n"
     ]
    }
   ],
   "source": [
    "print(climate_proposal_rankings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04eb07dcd94e49299aace343b44b8f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1870eb8083ef43838e21d9cbdf485e93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ae397d2d6c04acd80929a63d321a84b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9240e7b45bfb4806affa664c491c0971",
      "max": 5131409696,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e4305a1f8684745a6c549bbc8e27e4a",
      "value": 5131409696
     }
    },
    "30b74747ed4c4db784f29cc1eda1b797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1870eb8083ef43838e21d9cbdf485e93",
      "placeholder": "​",
      "style": "IPY_MODEL_04eb07dcd94e49299aace343b44b8f03",
      "value": " 5.13G/5.13G [00:36&lt;00:00, 120MB/s]"
     }
    },
    "36ed7ed1c8b3429496efa05cb33cb1cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bf81c0bff484b7e98bac2eae579ef3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f787ae6b8144581ad96c1ec919b85b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "795f3c6dc2e048109e5afd6e4b52bc6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8869bf759b85433ab3f4edd0cedb16a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9240e7b45bfb4806affa664c491c0971": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ee15a3eaa44f4b836b462e2c969a97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f129f14dd3f14f88940265511593b996",
       "IPY_MODEL_1ae397d2d6c04acd80929a63d321a84b",
       "IPY_MODEL_30b74747ed4c4db784f29cc1eda1b797"
      ],
      "layout": "IPY_MODEL_4bf81c0bff484b7e98bac2eae579ef3b"
     }
    },
    "9e4305a1f8684745a6c549bbc8e27e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a05f713b4e2c4956b5610fd1ada4c512": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6804cb24e3245a2b68b7ca5016464d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_795f3c6dc2e048109e5afd6e4b52bc6f",
      "placeholder": "​",
      "style": "IPY_MODEL_8869bf759b85433ab3f4edd0cedb16a1",
      "value": "llama-2-13b-chat.Q5_K_M.gguf: 100%"
     }
    },
    "b9d53223d8e0442ba94f19e773072483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bbb5a6640e594e50926ee5541e55f9fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccac73e43faf4b2aa9bae47b6ba09e58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4f8a3bd06bd4c34b47c9d1bca18e640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6804cb24e3245a2b68b7ca5016464d7",
       "IPY_MODEL_f9d7cdae14e746e6a9e2147bff90025a",
       "IPY_MODEL_de5f7ac281014fdd83e331ab70db2805"
      ],
      "layout": "IPY_MODEL_bbb5a6640e594e50926ee5541e55f9fc"
     }
    },
    "d6f14ce72aec4a26a74a30841008ca1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5f7ac281014fdd83e331ab70db2805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f787ae6b8144581ad96c1ec919b85b1",
      "placeholder": "​",
      "style": "IPY_MODEL_ccac73e43faf4b2aa9bae47b6ba09e58",
      "value": " 9.23G/9.23G [00:56&lt;00:00, 237MB/s]"
     }
    },
    "f129f14dd3f14f88940265511593b996": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6f14ce72aec4a26a74a30841008ca1c",
      "placeholder": "​",
      "style": "IPY_MODEL_36ed7ed1c8b3429496efa05cb33cb1cf",
      "value": "mistral-7b-instruct-v0.2.Q5_K_M.gguf: 100%"
     }
    },
    "f9d7cdae14e746e6a9e2147bff90025a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a05f713b4e2c4956b5610fd1ada4c512",
      "max": 9229924224,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9d53223d8e0442ba94f19e773072483",
      "value": 9229924224
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
